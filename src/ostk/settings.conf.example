# OSTK Agent settings.conf example
# Place this file at ~/.config/ostk/settings.conf (Linux/macOS)
# Or at ~/AppData/Local/ostk/settings.conf (Windows)

[llm]
# ===== Provider Selection =====
# Choose your LLM provider: openai, ollama, groq
# Default: openai
provider=openai

# ===== OpenAI Configuration =====
# Get your API key from: https://platform.openai.com/api-keys
openai_api_key=sk-...yourkey...
# Recommended models: gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo
openai_model=gpt-4o-mini

# ===== Ollama Configuration (Local, No API Key Required) =====
# Install Ollama from: https://ollama.ai
# Recommended models: llama3.1, llama3.1:70b, mixtral, codellama
# ollama_model=llama3.1
# ollama_base_url=http://localhost:11434

# ===== Groq Configuration =====
# Get your API key from: https://console.groq.com
# groq_api_key=gsk_...yourkey...
# Recommended models: llama-3.3-70b-versatile, llama-3.1-70b-versatile, mixtral-8x7b-32768
# groq_model=llama-3.3-70b-versatile
